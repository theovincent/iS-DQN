{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic \n",
    "# %black -l 120\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14da26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "from tests.flops_computation.dqn import DQN\n",
    "from tests.flops_computation.tfdqn import TFDQN\n",
    "from tests.flops_computation.isdqn import iSDQN\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "from tests.utils import Generator\n",
    "\n",
    "\n",
    "def count_params(params):\n",
    "\treturn sum(x.size for x in jax.tree.leaves(params))\n",
    "\n",
    "def get_memory_usage():\n",
    "\treturn int(sp.check_output([\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv\"]).decode('ascii').split(\"\\n\")[1].split(\" \")[0])\n",
    "\n",
    "def measure_memory_params(params):\n",
    "\tmemory = get_memory_usage()\n",
    "\tlist_params = jax.block_until_ready([jax.tree.map(lambda w: jnp.ones_like(w).astype(jnp.float32) * i, params) for i in range(1000)])\n",
    "\tmemory_params = (get_memory_usage() - memory) / 1000\n",
    "\tdel list_params\n",
    "\ttime.sleep(5)\n",
    "\n",
    "\treturn memory_params\n",
    "\n",
    "def count_flops(q, has_target_params=False):\n",
    "\tbest_action_compiled = jax.jit(q.best_action).lower(q.params, sample_generator.state(jax.random.PRNGKey(0)), key=jax.random.PRNGKey(0)).compile()\n",
    "\tif not has_target_params:\n",
    "\t\tlearn_on_batch_compiled = jax.jit(q.learn_on_batch).lower(q.params, q.optimizer_state, sample_generator.samples(jax.random.PRNGKey(0))).compile()\n",
    "\telse:\n",
    "\t\tlearn_on_batch_compiled = jax.jit(q.learn_on_batch).lower(q.params, q.target_params, q.optimizer_state, sample_generator.samples(jax.random.PRNGKey(0))).compile()\n",
    "\n",
    "\treturn best_action_compiled, learn_on_batch_compiled\n",
    "\n",
    "sample_generator = Generator(32, (84, 84, 4), 10) \n",
    "\n",
    "\n",
    "for architecture, features in [[\"cnn\", [32, 64, 64, 512]], [\"impala\", [32, 64, 64, 512]]]:\n",
    "\tprint(f\"--- {architecture} architecture ---\")\n",
    "\tq_dqn = DQN(jax.random.PRNGKey(0), (84, 84, 4), 10, features, True, architecture, 0.001, 0.9, 1, 1, 100)\n",
    "\tprint(\"TD-DQN\", count_params(q_dqn.params) * 2)\n",
    "\tq_dqn_best_action_compiled, q_dqn_learn_on_batch_compiled = count_flops(q_dqn, has_target_params=True)\n",
    "\tprint(\"FLOPs best action: \", q_dqn_best_action_compiled.cost_analysis()[0][\"flops\"])\n",
    "\tprint(\"FLOPs to learn on a batch: \", q_dqn_learn_on_batch_compiled.cost_analysis()[0][\"flops\"], \"\\n\")\n",
    "\n",
    "\ttfq_dqn = TFDQN(jax.random.PRNGKey(0), (84, 84, 4), 10, features, True, architecture, 0.001, 0.9, 1, 1, 100)\n",
    "\tprint(\"TF-DQN\", count_params(tfq_dqn.params))\n",
    "\ttfq_dqn_best_action_compiled, tfq_dqn_learn_on_batch_compiled = count_flops(tfq_dqn)\n",
    "\tprint(\"FLOPs best action: \", tfq_dqn_best_action_compiled.cost_analysis()[0][\"flops\"])\n",
    "\tprint(\"FLOPs to learn on a batch: \", tfq_dqn_learn_on_batch_compiled.cost_analysis()[0][\"flops\"], \"\\n\")\n",
    "\n",
    "\tmemory_tf = measure_memory_params(q_dqn.params)\n",
    "\tprint(f\"{memory_tf} Mb saved for TF\")\n",
    "\n",
    "\tfor K in [1, 4, 9, 49]:\n",
    "\t\tq_isdqn = iSDQN(jax.random.PRNGKey(0), (84, 84, 4), 10, K, features, True, architecture, 0, 0, 1, 1, 1, 1)\n",
    "\t\t\n",
    "\t\tprint(f\"iSDQN K={K}\", count_params(q_isdqn.params))\n",
    "\t\t# print(f\"{2 * memory_tf - measure_memory_params(q_isdqn.params)} Mb saved for iSDQN K={K}\")\n",
    "\t\tq_isdqn_best_action_compiled, q_isdqn_learn_on_batch_compiled = count_flops(q_isdqn)\n",
    "\t\tprint(\"FLOPs best action: \", q_isdqn_best_action_compiled.cost_analysis()[0][\"flops\"])\n",
    "\t\tprint(\"FLOPs to learn on a batch: \", q_isdqn_learn_on_batch_compiled.cost_analysis()[0][\"flops\"], \"\\n\")\n",
    "\tprint(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
